{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cc18039-048d-44f4-9b5f-b408158d52ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../utils/mount_configuration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe4fcf9a-b791-4e9b-a414-806ce4b00ed9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "evaluation_date = dbutils.jobs.taskValues.get(taskKey=\"tickers_quality_evaluation\", key=\"evaluation_date\", debugValue=\"2025-03-17\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df467b81-73a5-4869-85f4-0118bf8eb4ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tickers_dividend_df = spark.read.format('delta') \\\n",
    "                                 .load(f'{processed_folder_path}/tickers_dividend')\n",
    "\n",
    "display(tickers_dividend_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd8dd1e0-b860-405d-9eb0-ad117445682b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "warren_buffet_stocks_selection_df = spark.read.format('delta') \\\n",
    "                                              .load(f'{presentation_folder_path}/warren_buffet_stocks_selection') \\\n",
    "                                              .filter(col('date') == evaluation_date) \\\n",
    "                                              .select('ticker') \\\n",
    "                                              .distinct()\n",
    "\n",
    "display(warren_buffet_stocks_selection_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd1254ab-746b-4954-8ced-f9d904195fc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "benjamin_graham_stocks_selection = spark.read.format('delta') \\\n",
    "                                              .load(f'{presentation_folder_path}/benjamin_graham_stocks_selection') \\\n",
    "                                              .filter(col('date') == evaluation_date) \\\n",
    "                                              .select('ticker') \\\n",
    "                                              .distinct()\n",
    "\n",
    "display(benjamin_graham_stocks_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc7b6141-55ce-41de-bd38-41f9c3187346",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql.functions import col, sum, year\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def save_plot_to_data_lake(data, x_col, y_col, hue_col, title, xlabel, ylabel, filename):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=x_col, y=y_col, hue=hue_col, data=data, palette=\"coolwarm\")\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(xlabel, fontsize=14)\n",
    "    plt.ylabel(ylabel, fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.gcf().set_facecolor('white')\n",
    "    plt.savefig(f'/dbfs/{presentation_folder_path}/investment_recommendations/{evaluation_date}/{filename}.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "tickers_to_plot = [row['ticker'] for row in benjamin_graham_stocks_selection.select(\"ticker\").distinct().collect()]\n",
    "\n",
    "#Creation directory in which will be stored all files for each evalution date \n",
    "directory = f'{presentation_folder_path}/investment_recommendations/{evaluation_date}'\n",
    "dbutils.fs.mkdirs(directory)\n",
    "\n",
    "#Creation dataframe for last two years of dividends\n",
    "last_2_years_dividends_df = tickers_dividend_df \\\n",
    "    .filter(col(\"pay_date\") >= datetime(datetime.now().year - 2, 1, 1)) \\\n",
    "    .filter(col(\"ticker\").isin(tickers_to_plot)) \\\n",
    "    .groupBy(\"ticker\") \\\n",
    "    .agg(sum(\"cash_amount\").alias(\"total_dividends\")) \\\n",
    "    .toPandas()\n",
    "\n",
    "#Creation dataframe for the last 10 years of dividends per year for selected tickers\n",
    "df_last_10_years_dividends_per_year = tickers_dividend_df \\\n",
    "    .filter(col(\"pay_date\") >= datetime(datetime.now().year - 10, 1, 1)) \\\n",
    "    .withColumn(\"year\", year(col(\"pay_date\"))) \\\n",
    "    .groupBy(\"ticker\", \"year\") \\\n",
    "    .agg(sum(\"cash_amount\").alias(\"total_dividends_per_year\")) \\\n",
    "    .filter(col(\"ticker\").isin(tickers_to_plot)) \\\n",
    "    .toPandas()\n",
    "\n",
    "\n",
    "save_plot_to_data_lake(last_2_years_dividends_df, \"ticker\", \"total_dividends\", None, \n",
    "                       \"Sum of Dividends from the Last Two Years for Selected Tickers\",  \"Ticker\", \"Total Dividends per Share\",\n",
    "                       \"dividends_last_2_years_plot_benjamin_graham\")\n",
    "\n",
    "save_plot_to_data_lake(df_last_10_years_dividends_per_year, \"year\", \"total_dividends_per_year\", \"ticker\",\n",
    "                       \"Dividends Each Year for the Last 10 Years for Selected Tickers\", \"Year\", \"Sum of Dividends per Share for Each Year\",\n",
    "                       \"dividends_per_year_plot_benjamin_graham\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fef2683f-75ff-4216-a60e-251cdff64349",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(f'{presentation_folder_path}/investment_recommendations/{evaluation_date}/')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "count_tickers_dividends",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
