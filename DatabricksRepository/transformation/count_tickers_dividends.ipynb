{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5560f652-1e78-4050-8625-a51e1c72ee38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Counting dividends for tickers that have passed evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cc18039-048d-44f4-9b5f-b408158d52ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../utils/mount_configuration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe4fcf9a-b791-4e9b-a414-806ce4b00ed9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load evaluation date from 'tickers_quality_evaluation' task\n",
    "evaluation_date = dbutils.jobs.taskValues.get(taskKey=\"tickers_quality_evaluation\", key=\"evaluation_date\", debugValue=\"2025-03-17\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df467b81-73a5-4869-85f4-0118bf8eb4ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tickers_dividend_df = spark.read \\\n",
    "    .format('delta') \\\n",
    "    .load(f'{processed_folder_path}/tickers_dividend')\n",
    "\n",
    "# display(tickers_dividend_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd8dd1e0-b860-405d-9eb0-ad117445682b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "warren_buffet_stocks_selection_df = spark.read \\\n",
    "    .format('delta') \\\n",
    "    .load(f'{presentation_folder_path}/warren_buffet_stocks_selection') \\\n",
    "    .filter(col('date') == evaluation_date) \\\n",
    "    .select('ticker')\n",
    "\n",
    "# display(warren_buffet_stocks_selection_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd1254ab-746b-4954-8ced-f9d904195fc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "benjamin_graham_stocks_selection_df = spark.read \\\n",
    "    .format('delta') \\\n",
    "    .load(f'{presentation_folder_path}/benjamin_graham_stocks_selection') \\\n",
    "    .filter(col('date') == evaluation_date) \\\n",
    "    .select('ticker')\n",
    "\n",
    "# display(benjamin_graham_stocks_selection_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc7b6141-55ce-41de-bd38-41f9c3187346",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql.functions import sum, year\n",
    "from datetime import datetime\n",
    "\n",
    "# Generate and save a bar plot to the data lake\n",
    "def save_plot_to_data_lake(data, x_col, y_col, hue_col, title, xlabel, ylabel, filename):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=x_col, y=y_col, hue=hue_col, data=data, palette=\"coolwarm\")\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(xlabel, fontsize=14)\n",
    "    plt.ylabel(ylabel, fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.gcf().set_facecolor('white')\n",
    "    plt.savefig(f'/dbfs/{presentation_folder_path}/investment_recommendations/{evaluation_date}/{filename}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f8785cd-d746-4f2b-b3e9-2a122a5b7b08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def save_2yr_dividend_plot_for_tickers(tickers_to_plot, investment_philosophy):\n",
    "    \n",
    "    # Creation dataframe for last two years of dividends\n",
    "    last_2_years_dividends_df = tickers_dividend_df \\\n",
    "        .filter(col(\"pay_date\") >= datetime(datetime.now().year - 2, 1, 1)) \\\n",
    "        .filter(col(\"ticker\").isin(tickers_to_plot)) \\\n",
    "        .groupBy(\"ticker\") \\\n",
    "        .agg(sum(\"cash_amount\").alias(\"total_dividends\")) \\\n",
    "        .toPandas()\n",
    "    \n",
    "    save_plot_to_data_lake(last_2_years_dividends_df, \"ticker\", \"total_dividends\", None, \n",
    "                       \"Sum of Dividends from the Last Two Years for Selected Tickers\",  \"Ticker\", \"Total Dividends per Share\",\n",
    "                       f\"dividends_last_2_years_plot_{investment_philosophy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33e50264-17fa-4c37-9956-2699ab9025ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def save_dividends_per_year_plot_for_tickers(tickers_to_plot, investment_philosophy):\n",
    "\n",
    "    # Creation dataframe for the last 10 years of dividends per year for selected tickers\n",
    "    df_last_10_years_dividends_per_year = tickers_dividend_df \\\n",
    "        .filter(col(\"pay_date\") >= datetime(datetime.now().year - 10, 1, 1)) \\\n",
    "        .withColumn(\"year\", year(col(\"pay_date\"))) \\\n",
    "        .groupBy(\"ticker\", \"year\") \\\n",
    "        .agg(sum(\"cash_amount\").alias(\"total_dividends_per_year\")) \\\n",
    "        .filter(col(\"ticker\").isin(tickers_to_plot)) \\\n",
    "        .toPandas()\n",
    "    \n",
    "    save_plot_to_data_lake(df_last_10_years_dividends_per_year, \"year\", \"total_dividends_per_year\", \"ticker\",\n",
    "                       \"Dividends Each Year for the Last 10 Years for Selected Tickers\", \"Year\", \"Sum of Dividends per Share for Each Year\",\n",
    "                       f\"dividends_per_year_plot_{investment_philosophy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c1bca4b-9b26-407b-b370-d32c08c821ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get tickers to plot\n",
    "tickers_to_plot_benjamin_graham = [row['ticker'] for row in benjamin_graham_stocks_selection_df.select(\"ticker\").distinct().collect()]\n",
    "tickers_to_plot_warren_buffet = [row['ticker'] for row in warren_buffet_stocks_selection_df.select(\"ticker\").distinct().collect()]\n",
    "\n",
    "# Creation directory in which will be stored all files for each evalution date \n",
    "directory = f'{presentation_folder_path}/investment_recommendations/{evaluation_date}'\n",
    "dbutils.fs.mkdirs(directory)\n",
    "\n",
    "save_2yr_dividend_plot_for_tickers(tickers_to_plot_benjamin_graham, 'benjamin_graham')\n",
    "save_dividends_per_year_plot_for_tickers(tickers_to_plot_benjamin_graham, 'benjamin_graham')\n",
    "save_2yr_dividend_plot_for_tickers(tickers_to_plot_warren_buffet, 'warren_buffet')\n",
    "save_dividends_per_year_plot_for_tickers(tickers_to_plot_warren_buffet, 'warren_buffet')\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "count_tickers_dividends",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
